{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developmental-philippines",
   "metadata": {},
   "outputs": [],
   "source": [
    "using DataFrames, CSV, StatsPlots, Plots.Measures, Statistics, LaTeXStrings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thousand-validation",
   "metadata": {},
   "source": [
    "# Handling data from the TI impurity simulations\n",
    "In this notebook we want to show how the data files generated with our simulations for the two-dimensional Topological insulator with impurities can be handled to extract the desired information.\n",
    "\n",
    "The simulation saves several .csv files, specifically it creates a folder named with the date and within that folder it creates \n",
    "* a log file with the parameters used for the simulation in the first line and several timestamped lines with the progress of the simulation for monitoring during running the code\n",
    "* a number of .csv files that each contain the results of the simulation for one specific random impurity distribution\n",
    "\n",
    "## The .log file\n",
    "\n",
    "First we take a look at the log file.\n",
    "For this purpose we read the first line of the .log from the data folder (small sample of an actual results folder)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imported-organic",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = readline(\"data/2020-12-12/2020-12-12.log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decimal-injection",
   "metadata": {},
   "source": [
    "Most relevant for us will be the biggest Fourier coefficient $n_{max}$, so we store it in a variable to use later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brief-swift",
   "metadata": {},
   "outputs": [],
   "source": [
    "nmax = parse(Int, first(split(last(split(params,\"nmax=\")),\" ,\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comprehensive-newcastle",
   "metadata": {},
   "source": [
    "We see the time stamp when the simulation started and with what parameters.\n",
    "Note that one folder is created for each set of parameters, so this line can be used to automate the extraction of parameters and looping over several folders can be used to compare between parameters.\n",
    "\n",
    "If we look at the second line we see that it logged that 10 runs where completed.\n",
    "This is logged purely for information and monitoring purposes during the runs (the runs on a powerful desktop computer ran depending on parameters between several minutes to several days)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "steady-replacement",
   "metadata": {},
   "outputs": [],
   "source": [
    "readlines(\"data/2020-12-12/2020-12-12.log\")[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "personalized-confidentiality",
   "metadata": {},
   "source": [
    "## The .csv files\n",
    "\n",
    "The .csv files contain the results of the simulation for one specific impurity configuration.\n",
    "More specifically it contains\n",
    "\n",
    "* the energy grid that will be the x-axis of most plots\n",
    "* all calculated Green's function components that appear in the Floquet scattering matrix of the problem\n",
    "* the Density of states at the impurity closest to the center\n",
    "* the Density of states at the center of the impurity region\n",
    "* the transmission from the left to the right end of the impurity region (T_RL)\n",
    "* the transmission from the right to the left end of the impurity region (T_LR)\n",
    "\n",
    "In principle the transmissions and density of states can be calculated from the Green's function components, but for convenience this has already been done.\n",
    "\n",
    "Now let's load up one of the .csv files.\n",
    "Note, that the Green's function components are complex numbers, so we specify the types for the columns.\n",
    "The first two columns are going to be Floats, followed by $6 \\cdot (2 n_{max}+1)$ ComplexFloats (6 for components between left and right, right and left, left and left, right and right, two times from center to center (spin) and $(2 n_{max}+1)$ for $n_{max}$ Fourier components positive/negative and zero) and the remaining three columns are Floats again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blessed-round",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=DataFrame(CSV.File(\"data/2020-12-12/2020-12-12_1.csv\",types=[Float64, Float64, [Complex{Float64} for i=1:(2*nmax+1)*6]...,Float64, Float64, Float64]))\n",
    "first(df,5) # show only first 5 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bigger-accreditation",
   "metadata": {},
   "source": [
    "# Impurity averaging\n",
    "We can now read the data for one specific impurity configuration.\n",
    "Since we want to do impurity averaging we need to read the other files in the folder and in this case we will append them all to the same DataFrame and add a series index for each series.\n",
    "We will use the number appended to the filename to number the configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grand-ready",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = filter(x -> x[end-3:end] == \".csv\", readdir(\"data/2020-12-12/\")) # create vector containing the filenames\n",
    "data = DataFrame() # initialize empty dataframe\n",
    "for i in files # loop over files\n",
    "    # prepare dataframe\n",
    "    df = DataFrame(CSV.File(\"data/2020-12-12/\"*i,types=[Float64, Float64, [Complex{Float64} for i=1:(2*nmax+1)*6]...,Float64, Float64, Float64])) # read the .csv as dataframe\n",
    "    s = parse(Int,last(split(first(split(i,'.')),'_'))) # extract series number from filename\n",
    "    df[!, :series] = [s for k in 1:size(df)[1]] # label series in dataframe, could also add potential or other things\n",
    "    # append the prepared df to main dataframe\n",
    "    append!(data,df)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advanced-namibia",
   "metadata": {},
   "source": [
    "Our goal is now get the impurity averaged transmission $T_RL$ (from left to right) and also the density of states $DOS$ at the center depending on the energy $E$ scaled in units of the expected gap in the static case $\\Delta$.\n",
    "We can get that by simply grouping the data by the energy, i.e. get separate DataFrames for every energy and use the combine function to average and combine into the data we are interested in\n",
    "(This follows the split-apply-combine logic, further reading [here](https://dataframes.juliadata.org/stable/man/split_apply_combine/))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "drawn-gasoline",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = groupby(data,:E)\n",
    "result = combine(gdf,:T_RL => mean, :DOS => mean)\n",
    "first(result,5) # show only first 5 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "russian-sector",
   "metadata": {},
   "source": [
    "We can save the resulting dataframe as a .csv using the CSV package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "concrete-benefit",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV.write(\"impavg.csv\",result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charming-shell",
   "metadata": {},
   "source": [
    "## Plots\n",
    "To plot the prepared data we can use the plot recipes that the StatPlots-Package provides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "separate-profile",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt1 = begin\n",
    "    # plot reciept for initial plot\n",
    "    @df result plot(:E,:T_RL_mean)\n",
    "    # refine plot\n",
    "    plot!(legend = false, xlabel = L\"E/\\Delta\", ylabel = L\"T_{RL}(E)\")\n",
    "    plot!(title = \"Impurity averaged transmission\")\n",
    "end\n",
    "plt2 = begin\n",
    "    # plot reciept for initial plot\n",
    "    @df result plot(:E,:DOS_mean)\n",
    "    # refine plot\n",
    "    plot!(legend=false,xlabel=L\"E/\\Delta\",ylabel=L\"DOS(E)\")\n",
    "    plot!(title = \"Impurity averaged density of states\")\n",
    "end\n",
    "# composite plot with the two plots prepared above\n",
    "plot(plt1, plt2, layout = (1,2), size = (900,300), left_margin = [5mm 5mm], bottom_margin = [5mm 5mm])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indoor-genesis",
   "metadata": {},
   "source": [
    "Now we may want to see the difference between the impurity averaged results and the non-averaged traces.\n",
    "For that we can group the data by the series index we added earlier and plot those traces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forced-fusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt1 = begin\n",
    "    plot() # initialize plot canvas\n",
    "    for i in groupby(data,:series) # loop over the series in our dataframe\n",
    "        @df i plot!(:E,:DOS) \n",
    "    end \n",
    "    # refine plot\n",
    "    plot!(legend=false,xlabel=L\"E/\\Delta\",ylabel=L\"DOS(E)\")\n",
    "    plot!(title = \"Density of states\")\n",
    "end\n",
    "plt2 = begin\n",
    "    plot() # initialize plot canvas\n",
    "    for i in groupby(data,:series) # loop over the series in our dataframe\n",
    "        @df i plot!(:E,:T_RL) # add the series to the canvas\n",
    "    end\n",
    "    # refine plot\n",
    "    plot!(legend=false,xlabel=L\"E/\\Delta\",ylabel=L\"T_{RL}(E)\")\n",
    "    plot!(title = \"Transmission\")\n",
    "end\n",
    "# composite plot with the two plots prepared above\n",
    "plot(plt1, plt2, layout = (1,2), size = (900,300), left_margin = [5mm 5mm], bottom_margin = [5mm 5mm])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compatible-ethernet",
   "metadata": {},
   "source": [
    "To understand the effect the impurity averaging has we can also plot a few non-averaged traces next to the averaged results.\n",
    "For that we can make use of the layout macro for more complicated composite plots and also the series index we added to the data earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corporate-mills",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = @layout([a{0.6w} [b{0.35w,0.3h}; c{0.35w,0.3h}; d{0.35w,0.3h}]]) # set the layout\n",
    "# create 3 single distribution plots\n",
    "single=[] # initialize containter for subplots\n",
    "for i in 1:3 \n",
    "    d = groupby(data,:series)[i] # group data by series\n",
    "    push!(single,@df d plot(:E,:T_RL,legend = false, widen = false, ylims = (0.,0.8),yticks=[0.0,0.4])) # append plot to container\n",
    "    # some layouting depending on final position in the plot\n",
    "    if i == 1\n",
    "        plot!(xticks=[], top_margin = 8mm)\n",
    "    elseif i == 2\n",
    "        plot!(xticks=[])\n",
    "    else\n",
    "        plot!(xlabel = L\"E/\\Delta\")\n",
    "    end\n",
    "end\n",
    "# impurity averaged plot\n",
    "avg = @df result plot(:E,:T_RL_mean,legend = false, xlabel = L\"E/\\Delta\", ylabel = L\"T_{RL}(E)\",left_margin = [5mm 5mm], title = \"Averaged transmission along\\n some single distribution traces\")\n",
    "# final plot\n",
    "plot(avg,single...,layout = l,size=(900,400),bottom_margin = 5mm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "narrative-bikini",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.6.0",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
